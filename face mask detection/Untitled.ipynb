{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow\n",
    "\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense,Conv2D,AveragePooling2D,Flatten,MaxPooling2D,BatchNormalization,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(featurewise_center = True,\n",
    "                                  featurewise_std_normalization = True,\n",
    "                                  samplewise_center = False,\n",
    "                                  rotation_range = 45,width_shift_range=0.4 ,\n",
    "                                  height_shift_range = 0.4,brightness_range=[-0.2,1.2],shear_range=4,rescale=1./255\n",
    "                                  )\n",
    "test_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "final_train_gen = train_gen.flow_from_directory(r\"C:\\Users\\LAKSHMI NARASIMHARAO\\innomatics\\Deep Learning\\Projects\\kaggle (mask detection)\\Train\",\n",
    "                              target_size=(227,227),class_mode='sparse',batch_size=90)\n",
    "\n",
    "final_test_gen = test_gen.flow_from_directory(r\"C:\\Users\\LAKSHMI NARASIMHARAO\\innomatics\\Deep Learning\\Projects\\kaggle (mask detection)\\Validation\",\n",
    "                              target_size=(227,227),class_mode='sparse',batch_size=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(227, 227, 3))\n",
    "\n",
    "conv1 = Conv2D(96, (11,11), strides=(4, 4), padding='valid', activation='relu')(input_layer)\n",
    "max_pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(conv1)\n",
    "bn1 = BatchNormalization()(max_pool1)\n",
    "\n",
    "conv2 = Conv2D(256, (5, 5), strides=(1, 1), padding='same', activation='relu')(bn1)\n",
    "max_pool2 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(conv2)\n",
    "bn2 = BatchNormalization()(max_pool2)\n",
    "\n",
    "\n",
    "conv3 = Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu')(bn2)\n",
    "bn3 = BatchNormalization()(conv3)\n",
    "\n",
    "conv4 = Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu')(bn3)\n",
    "bn4 = BatchNormalization()(conv4)\n",
    "\n",
    "conv5 = Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu')(bn4)\n",
    "max_pool3 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(conv5)\n",
    "bn5 = BatchNormalization()(max_pool3)\n",
    "\n",
    "\n",
    "flatten = Flatten()(bn5)\n",
    "\n",
    "hidd1 = Dense(9216, activation='relu')(flatten)\n",
    "hidd2 = Dense(4096, activation='relu')(hidd1)\n",
    "d1 = Dropout(rate=0.5)(hidd2)\n",
    "hidd3 = Dense(4096, activation='relu')(d1)\n",
    "d2 = Dropout(rate=0.5)(hidd3)\n",
    "\n",
    "output_layer = Dense(2, activation='softmax')(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "atex_model = Model(inputs = input_layer,outputs = output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 227, 227, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 27, 27, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 27, 27, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 13, 13, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 13, 13, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 9216)              84943872  \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 143,238,914\n",
      "Trainable params: 143,236,162\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "atex_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "111/111 [==============================] - 985s 9s/step - loss: 3.3288 - accuracy: 0.6911 - val_loss: 0.4907 - val_accuracy: 0.7819\n",
      "Epoch 2/10\n",
      "111/111 [==============================] - 883s 8s/step - loss: 0.4934 - accuracy: 0.7663 - val_loss: 0.5715 - val_accuracy: 0.6889\n",
      "Epoch 3/10\n",
      "111/111 [==============================] - 1067s 10s/step - loss: 0.4744 - accuracy: 0.7775 - val_loss: 0.4605 - val_accuracy: 0.7708\n",
      "Epoch 4/10\n",
      "111/111 [==============================] - 1185s 11s/step - loss: 0.4611 - accuracy: 0.7907 - val_loss: 0.2428 - val_accuracy: 0.9333\n",
      "Epoch 5/10\n",
      "111/111 [==============================] - 1180s 11s/step - loss: 0.4523 - accuracy: 0.7911 - val_loss: 0.4068 - val_accuracy: 0.8861\n",
      "Epoch 6/10\n",
      "111/111 [==============================] - 1000s 9s/step - loss: 0.4223 - accuracy: 0.8000 - val_loss: 0.2849 - val_accuracy: 0.8917\n",
      "Epoch 7/10\n",
      "111/111 [==============================] - 883s 8s/step - loss: 0.4149 - accuracy: 0.8040 - val_loss: 0.6772 - val_accuracy: 0.4764\n",
      "Epoch 8/10\n",
      "111/111 [==============================] - 1198s 11s/step - loss: 0.4015 - accuracy: 0.8160 - val_loss: 0.3231 - val_accuracy: 0.9125\n",
      "Epoch 9/10\n",
      "111/111 [==============================] - 899s 8s/step - loss: 0.4041 - accuracy: 0.8114 - val_loss: 0.9465 - val_accuracy: 0.5319\n",
      "Epoch 10/10\n",
      "111/111 [==============================] - 996s 9s/step - loss: 0.3961 - accuracy: 0.8090 - val_loss: 0.2221 - val_accuracy: 0.9167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1831c812648>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atex_model.compile(optimizer='adam',loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "atex_model.fit_generator(final_train_gen,steps_per_epoch=10000//90,epochs=10,\n",
    "                         validation_data=final_test_gen,validation_steps=800//90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 11s 1s/step - loss: 0.2244 - accuracy: 0.9175\n",
      "Test Loss: 0.22442694008350372\n",
      "Test Accuracy: 0.9175000190734863\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = atex_model.evaluate(final_test_gen)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "atex_model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = tensorflow.keras.models.load_model(\"final_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WithMask': 0, 'WithoutMask': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1163.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for file_name in os.listdir(r'C:\\Users\\LAKSHMI NARASIMHARAO\\innomatics\\Deep Learning\\Projects\\kaggle (mask detection)\\Test\\WithMask'):\n",
    "    print(file_name)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(r\"C:\\Users\\LAKSHMI NARASIMHARAO\\innomatics\\Deep Learning\\Projects\\kaggle (mask detection)\\Test\\WithMask\\152.png\")\n",
    "\n",
    "np.argmax(my_model.predict(cv2.resize(img,(227,227))[np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_model = cv2.CascadeClassifier(r\"C:\\Users\\LAKSHMI NARASIMHARAO\\innomatics\\Deep Learning\\opencv\\haarcascade_frontalface_alt.xml\")\n",
    "for x,y,w,h in face_model.detectMultiScale(img):\n",
    "    if np.argmax(my_model.predict(cv2.resize(img,(227,227))[np.newaxis])) == 0:\n",
    "        cv2.putText(img,'Mask',(x+10,y+10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0))\n",
    "    else:\n",
    "        cv2.putText(img,' No Mask',(x+10,y+10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "count=0\n",
    "for file_name in os.listdir(r'C:\\Users\\LAKSHMI NARASIMHARAO\\innomatics\\Deep Learning\\Projects\\kaggle (mask detection)\\Test\\WithMask'):\n",
    "    img = cv2.imread(r\"C:\\Users\\LAKSHMI NARASIMHARAO\\innomatics\\Deep Learning\\Projects\\kaggle (mask detection)\\Test\\WithMask\\{}\".format(file_name))\n",
    "    face_model = cv2.CascadeClassifier(r\"C:\\Users\\LAKSHMI NARASIMHARAO\\innomatics\\Deep Learning\\opencv\\haarcascade_frontalface_alt.xml\")\n",
    "    for x,y,w,h in face_model.detectMultiScale(img):\n",
    "        if np.argmax(my_model.predict(cv2.resize(img,(227,227))[np.newaxis])) == 0:\n",
    "            cv2.putText(img,'Mask',(x+10,y+10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0))\n",
    "        else:\n",
    "            cv2.putText(img,' No Mask',(x+10,y+10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0))\n",
    "    if count<10:\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey()\n",
    "        cv2.destroyAllWindows()\n",
    "        count+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG19 and VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "312/312 [==============================] - 2237s 7s/step - loss: 0.2436 - accuracy: 0.9614 - val_loss: 0.0182 - val_accuracy: 0.9912\n",
      "Epoch 2/10\n",
      "312/312 [==============================] - 3324s 11s/step - loss: 0.0343 - accuracy: 0.9884 - val_loss: 0.1142 - val_accuracy: 0.9500\n",
      "Epoch 3/10\n",
      "312/312 [==============================] - 3118s 10s/step - loss: 0.0327 - accuracy: 0.9888 - val_loss: 0.0269 - val_accuracy: 0.9925\n",
      "Epoch 4/10\n",
      "312/312 [==============================] - 2350s 8s/step - loss: 0.0265 - accuracy: 0.9899 - val_loss: 0.0188 - val_accuracy: 0.9962\n",
      "Epoch 5/10\n",
      "312/312 [==============================] - 2237s 7s/step - loss: 0.0277 - accuracy: 0.9896 - val_loss: 0.0079 - val_accuracy: 0.9975\n",
      "Epoch 6/10\n",
      "312/312 [==============================] - 3428s 11s/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 0.0070 - val_accuracy: 0.9987\n",
      "Epoch 7/10\n",
      "312/312 [==============================] - 2890s 9s/step - loss: 0.0270 - accuracy: 0.9907 - val_loss: 0.0078 - val_accuracy: 0.9987\n",
      "Epoch 8/10\n",
      "312/312 [==============================] - 2633s 8s/step - loss: 0.0198 - accuracy: 0.9929 - val_loss: 0.0083 - val_accuracy: 0.9962\n",
      "Epoch 9/10\n",
      "312/312 [==============================] - 5483s 18s/step - loss: 0.0215 - accuracy: 0.9916 - val_loss: 0.0261 - val_accuracy: 0.9937\n",
      "Epoch 10/10\n",
      "312/312 [==============================] - 2786s 9s/step - loss: 0.0211 - accuracy: 0.9925 - val_loss: 0.0050 - val_accuracy: 0.9975\n",
      "Epoch 1/10\n",
      "153/312 [=============>................] - ETA: 24:15 - loss: 0.4721 - accuracy: 0.9130"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0462d7428d6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m )\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16, VGG19\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Constants\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# Load pre-trained models\n",
    "base_model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model_vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers\n",
    "for layer in base_model_vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in base_model_vgg19.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create model architecture\n",
    "model_vgg16 = Sequential([\n",
    "    base_model_vgg16,\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "model_vgg19 = Sequential([\n",
    "    base_model_vgg19,\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the models\n",
    "model_vgg16.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_vgg19.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Data preprocessing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\LAKSHMI NARASIMHARAO\\innomatics\\Deep Learning\\Projects\\kaggle (mask detection)\\Train\",\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        r\"C:\\Users\\LAKSHMI NARASIMHARAO\\innomatics\\Deep Learning\\Projects\\kaggle (mask detection)\\Validation\",\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Train the models\n",
    "history_vgg16 = model_vgg16.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Evaluate the models\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\LAKSHMI NARASIMHARAO\\innomatics\\Deep Learning\\Projects\\kaggle (mask detection)\\Test\",\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "history_vgg19 = model_vgg19.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16.save('mask_detection_vgg16.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WithMask': 0, 'WithoutMask': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 992 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\LAKSHMI NARASIMHARAO\\innomatics\\Deep Learning\\Projects\\kaggle (mask detection)\\Test\",\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 192s 6s/step - loss: 0.0086 - accuracy: 0.9980\n",
      "VGG16 Test Loss: 0.008588694036006927\n",
      "VGG16 Test Accuracy: 0.9979838728904724\n"
     ]
    }
   ],
   "source": [
    "vgg16_scores = model_vgg16.evaluate(test_generator)\n",
    "print(\"VGG16 Test Loss:\", vgg16_scores[0])\n",
    "print(\"VGG16 Test Accuracy:\", vgg16_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 152s 6s/step - loss: 0.0050 - accuracy: 0.9975\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vgg19_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ee5fd92adf90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvgg16_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_vgg16\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"VGG16 validation Loss:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvgg19_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"VGG16 validation Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvgg19_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vgg19_scores' is not defined"
     ]
    }
   ],
   "source": [
    "vgg16_scores = model_vgg16.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16 validation Loss: 0.0050130062736570835\n",
      "VGG16 validation Accuracy: 0.9975000023841858\n"
     ]
    }
   ],
   "source": [
    "print(\"VGG16 validation Loss:\", vgg16_scores[0])\n",
    "print(\"VGG16 validation Accuracy:\", vgg16_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = tensorflow.keras.models.load_model(\"mask_detection_vgg16.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(r\"C:\\Users\\LAKSHMI NARASIMHARAO\\innomatics\\Deep Learning\\Projects\\kaggle (mask detection)\\Test\\WithMask\\3.png\")\n",
    "\n",
    "np.argmax(final_model.predict(cv2.resize(img,(224,224),interpolation=cv2.INTER_AREA)[np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_model = cv2.CascadeClassifier(r\"C:\\Users\\LAKSHMI NARASIMHARAO\\innomatics\\Deep Learning\\opencv\\haarcascade_frontalface_alt.xml\")\n",
    "for x,y,w,h in face_model.detectMultiScale(img):\n",
    "    if np.argmax(final_model.predict(cv2.resize(img,(224,224))[np.newaxis])) == 0:\n",
    "        cv2.putText(img,'Mask',(x+10,y+10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0))\n",
    "    else:\n",
    "        cv2.putText(img,' No Mask',(x+10,y+10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img',cv2.resize(img,(224,224),interpolation=cv2.INTER_LINEAR))\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
